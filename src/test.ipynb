{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 테스트셋 로딩 ===\n",
      "테스트셋에서 10000개의 (q_id, a_id) 쌍을 로드했습니다.\n",
      "\n",
      "=== 원본 데이터 로딩 ===\n",
      "원본 데이터에서 61825개의 질문을 로드했습니다.\n",
      "\n",
      "=== DPO 선호도 쌍 생성 ===\n",
      "테스트셋과 중복되어 제외된 답변 수: 10000개\n",
      "\n",
      "=== 선호도 쌍 생성 결과 ===\n",
      "총 쌍 개수: 19,744개\n",
      "관련 질문 수: 14,312개\n",
      "평균 질문당 쌍 수: 1.38개\n",
      "\n",
      "=== 쌍 유형별 분포 ===\n",
      "채택된 전문가 vs 채택되지 않은 전문가: 0개\n",
      "채택된 전문가 vs 채택되지 않은 일반인: 1,907개\n",
      "채택된 일반인 vs 채택되지 않은 전문가: 133개\n",
      "채택된 일반인 vs 채택되지 않은 일반인: 17,704개\n",
      "\n",
      "결과가 ./dpo_preference_pairs.json에 저장되었습니다.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로딩 중: /home/work/factchecking/PetQA/data/processed/train.json\n",
      "  - 35380개 샘플 로드 완료\n",
      "로딩 중: /home/work/factchecking/PetQA/data/processed/validation.json\n",
      "  - 10000개 샘플 로드 완료\n",
      "총 45380개의 전처리 정보를 로드했습니다.\n",
      "16435개의 답변에 대해 전처리 정보를 찾았습니다.\n",
      "\n",
      "전처리 정보가 추가된 선호도 쌍: 19744개\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== preprocessed_question 필터링 ===\n",
      "빈 preprocessed_question으로 인해 제거된 샘플: 3309개\n",
      "필터링 후 남은 샘플: 16435개\n",
      "원본 샘플 수: 19,744개\n",
      "필터링 후 샘플 수: 16,435개\n",
      "제거율: 16.76%\n",
      "\n",
      "필터링된 결과가 ./dpo_preference_pairs_filtered.json에 저장되었습니다.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.886217948717949\n",
      "7.113381410256411\n",
      "3.9915865384615383\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "file_path = \"/home/work/factchecking/PetQA/outputs/results/atomic_facts/output_exaone-3.5-7.8b_0_preprocessed_E.json\"\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "expert_data_E = [item for item in data if item['answer_type'] == 'expert']\n",
    "expert_answer_len_E = [item['facts_count_predicted_answer'] for item in expert_data_E]\n",
    "\n",
    "file_path = \"/home/work/factchecking/PetQA/outputs/results/atomic_facts/output_exaone-3.5-7.8b_6_preprocessed.json\"\n",
    "with open(file_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "expert_data_base = [item for item in data if item['answer_type'] == 'expert']\n",
    "expert_answer_len_base = [item['facts_count_predicted_answer'] for item in expert_data_base]\n",
    "reference_answer_len_base = [item['facts_count_reference_answer'] for item in expert_data_base]\n",
    "\n",
    "print(sum(expert_answer_len_E) / len(expert_data_E))\n",
    "print(sum(expert_answer_len_base) / len(expert_data_base))\n",
    "print(sum(reference_answer_len_base) / len(expert_data_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog-nonexpert': 4541, 'cat-nonexpert': 2963, 'dog-expert': 2083, 'cat-expert': 413}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"/home/work/factchecking/PetQA/outputs/results/atomic_facts/output_gpt-4o-mini_3_preprocessed.json\"\n",
    "with open(file_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "category_cnt = {}\n",
    "for item in data:\n",
    "    category = f\"{item['animal_type']}-{item['answer_type']}\"\n",
    "    if category not in category_cnt:\n",
    "        category_cnt[category] = 0\n",
    "    category_cnt[category] += 1\n",
    "print(category_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: dog-expert\n",
      "  Factuality: 0.472\n",
      "Category: dog-nonexpert\n",
      "  Factuality: 0.402\n",
      "Category: cat-expert\n",
      "  Factuality: 0.477\n",
      "Category: cat-nonexpert\n",
      "  Factuality: 0.382\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "eval_dir = \"/home/work/factchecking/PetQA/outputs/results/atomic_facts\"\n",
    "file_path = os.path.join(eval_dir, \"output_gpt-4o-mini_3_preprocessed.json\")\n",
    "with open(file_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "unique_categories = [(\"dog\", \"expert\"), (\"dog\", \"nonexpert\"), (\"cat\", \"expert\"), (\"cat\", \"nonexpert\")]\n",
    "for animal_type, answer_type in unique_categories:\n",
    "    category = f\"{animal_type}-{answer_type}\"\n",
    "    print(f\"Category: {category}\")\n",
    "    \n",
    "    filtered_responses = [item for item in data \n",
    "                            if item[\"animal_type\"] == animal_type and item[\"answer_type\"] == answer_type]\n",
    "    \n",
    "    category_f1_scores = []\n",
    "    for response in filtered_responses:\n",
    "        precision = response[\"support_predicted_answer\"] / response[\"facts_count_predicted_answer\"] if response[\"facts_count_predicted_answer\"] > 0 else 0\n",
    "        recall = response[\"support_reference_answer\"] / response[\"facts_count_reference_answer\"] if response[\"facts_count_reference_answer\"] > 0 else 0\n",
    "        f1_score = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "        category_f1_scores.append(f1_score)\n",
    "    avg_f1_score = (sum(category_f1_scores) / len(category_f1_scores))\n",
    "    print(f\"  Factuality: {avg_f1_score:.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9818\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"/home/work/factchecking/PetQA/outputs/results/generated_answers/output_gemini-2.0-flash_6_raw.json\"\n",
    "with open(file_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "\n",
    "def count_chat_tokens(messages):\n",
    "    encoding = tiktoken.encoding_for_model('gpt-4o-mini')\n",
    "    tokens_per_message = 3  # role + content + 구조적 오버헤드\n",
    "    tokens_per_name = 1     # name 필드\n",
    "\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # assistant 응답 시작 오버헤드\n",
    "    return num_tokens\n",
    "\n",
    "def count_output_tokens(output_dict):\n",
    "    encoding = tiktoken.encoding_for_model('gpt-4o-mini')\n",
    "    json_string = json.dumps(output_dict, ensure_ascii=False)\n",
    "    return len(encoding.encode(json_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "입력으로 질문, 참조 답변, 예측 답변을 받게 됩니다.\n",
    "다음 단계에 따라 예측 답변을 참조 답변과 비교하여 정확성을 확인하세요:\n",
    "1. 예측 답변을 독립적인 사실들로 나눕니다. 각 독립적인 사실은 별도의 문장이어야 합니다.\n",
    "2. 각 독립적인 사실이 참조 답변에 의해 뒷받침되는지 개별적으로 평가합니다. 이때 추가적인 배경 지식을 사용하지 마세요.\n",
    "3. 다음으로, 참조 답변을 독립적인 사실들로 나눕니다. 각 독립적인 사실은 별도의 문장이어야 합니다.\n",
    "4. 각 독립적인 사실이 예측 답변에 의해 뒷받침되는지 개별적으로 평가합니다. 이때 추가적인 배경 지식을 사용하지 마세요.\n",
    "5. 마지막으로 (1.) 참조 답변에 의해 뒷받침되는 예측 사실의 수, (2.) 예측 답변에 의해 뒷받침되는 참조 사실의 수를 요약하세요.\n",
    "\n",
    "아래 예시를 참고하여 JSON 형식으로 출력하세요.\n",
    "\n",
    "### 예시\n",
    "질문: 강아지가 푸들인데 지금 6개월 되었습니다. 다른 이빨은 다 유치가 빠졌는데 송곳니만 아직 안 빠졌습니다. 흔들림도 전혀 없고, 영구치가 바로 옆에 또 나고 있는데 어떻게 해야 하나요?\n",
    "참조 답변: 강아지의 유치는 5~9개월 사이에 빠지는 것으로 알려져 있습니다. 10개월령까지 기다려 보셔도 괜찮을 것 같습니다. 10개월이 지났는데 빠지지 않는다면 병원에 내원하셔서 발치를 해야 합니다. 지금 시기에는 충분히 유치와 영구치가 같이 존재할 수 있는 시기이므로, 너무 걱정하지 마시고 조금 더 기다려 주시면 좋을 것 같습니다.\n",
    "예측 답변: 강아지의 송곳니가 아직 빠지지 않고 영구치가 나오는 경우는 종종 발생합니다. 이럴 때는 유치가 자연스럽게 빠지지 않을 수 있으므로, 송곳니가 흔들리지 않는다면 수의사에게 검진을 받는 것이 좋습니다. 수의사는 유치가 빠지지 않는 원인을 확인하고 필요시 제거할 수 있습니다. 방치할 경우 치아 배열에 문제가 생길 수 있으니 조기에 상담하는 것이 중요합니다.\n",
    "출력: \n",
    "{{\n",
    "    \"facts in predicted answer\": \"1. 강아지 송곳니가 빠지지 않고 영구치가 나오는 경우는 종종 발생합니다. 2. 유치가 자연스럽게 빠지지 않을 수 있습니다. 3. 송곳니가 흔들리지 않는다면 수의사에게 검진을 받는 것이 좋습니다. 4. 수의사는 유치가 빠지지 않는 원인을 확인하고 필요시 제거할 수 있습니다. 5. 방치할 경우 치아 배열에 문제가 생길 수 있으니 조기에 상담하는 것이 중요합니다.\",\n",
    "    \"fact check predicted answer\": \"1. 강아지 송곳니가 빠지지 않고 영구치가 나오는 경우는 종종 발생합니다. 참조 답변에서 '지금 시기에는 충분히 유치와 영구치가 같이 존재할 수 있는 시기'라고 언급되어 이 사실을 뒷받침합니다. 2. 유치가 자연스럽게 빠지지 않을 수 있습니다. 참조 답변에 이 내용이 직접적으로 언급되지는 않지만, '10개월이 지났는데 빠지지 않는다면 발치를 해야 한다'는 점에서 유추할 수 있습니다. 충분한 정보 없음. 3. 송곳니가 흔들리지 않는다면 수의사에게 검진을 받는 것이 좋습니다. 참조 답변에서 '10개월이 지났는데 빠지지 않는다면 병원에 내원하여 발치해야 한다'고 언급되어 이 사실을 뒷받침합니다. 4. 수의사는 유치가 빠지지 않는 원인을 확인하고 필요시 제거할 수 있습니다. 참조 답변에서 '발치를 해야 한다'고 언급되어 이 사실을 뒷받침합니다. 5. 방치할 경우 치아 배열에 문제가 생길 수 있으니 조기에 상담하는 것이 중요합니다. 참조 답변에서 유치를 방치했을 때 발생할 수 있는 문제에 대해 직접적으로 언급하지 않습니다. 충분한 정보 없음.\",\n",
    "    \"facts count predicted answer\": 5,\n",
    "    \"support predicted answer\": 3,\n",
    "    \"facts in reference answer\": \"1. 강아지 유치는 5~9개월 사이에 빠집니다. 2. 10개월령까지 기다려 볼 수 있습니다. 3. 10개월이 지나도 빠지지 않으면 병원에 내원하여 발치해야 합니다. 4. 지금 시기에는 유치와 영구치가 같이 존재할 수 있습니다. 5. 너무 걱정하지 말고 조금 더 기다려 주는 것이 좋습니다.\",\n",
    "    \"fact check reference answer\": \"1. 강아지 유치는 5~9개월 사이에 빠집니다. 예측 답변에서 이 시기에 대한 구체적인 언급은 없지만, 유치가 자연스럽게 빠지지 않을 수 있다는 전제를 통해 간접적으로 관련될 수 있습니다. 충분한 정보 없음. 2. 10개월령까지 기다려 볼 수 있습니다. 예측 답변에서 기다리는 것에 대한 직접적인 언급은 없으나, 흔들리지 않는다면 수의사 검진을 권유합니다. 충분한 정보 없음. 3. 10개월이 지나도 빠지지 않으면 병원에 내원하여 발치해야 합니다. 예측 답변에서 '수의사에게 검진을 받는 것이 좋다'고 언급하며 필요시 제거할 수 있다고 하여 이 사실을 뒷받침합니다. 4. 지금 시기에는 유치와 영구치가 같이 존재할 수 있습니다. 예측 답변에서 '송곳니가 아직 빠지지 않고 영구치가 나오는 경우는 종종 발생합니다'라고 언급하여 이 사실을 뒷받침합니다. 5. 너무 걱정하지 말고 조금 더 기다려 주는 것이 좋습니다. 예측 답변에서는 조기 상담을 강조하므로 이 사실과 상충될 수 있습니다. 충분한 정보 없음.\",\n",
    "    \"facts count reference answer\": 5,\n",
    "    \"support reference answer\": 2\n",
    "}}\n",
    "\n",
    "질문: 암컷 고양이를 키우고 있는데 중성화를 평생 안 하고 키워도 괜찮을까요?\n",
    "참조 답변: 강아지나 고양이는 수컷, 암컷 모두 중성화수술이 필요합니다. 수컷의 경우에는 행동장애와 전립선염, 전립선암, 항문선종과 같은 생식기질환을 예방하고 암컷은 생리와 유선종양, 자궁축농증, 난소종양과 같은 생식기질환을 예방할 수 있습니다. 생리불순인 상황에서는 위험성은 증가하므로 중성화수술이 더욱 중요하고 가출방지와 성격순화에도 도움이 됩니다. 일반적으로 중성화수술은 생후 7개월 전후로 시행합니다.\n",
    "예측 답변: 암컷 고양이를 중성화하지 않고 키우는 것은 여러 가지 위험을 동반할 수 있습니다. 첫째, 발정 주기가 반복되면서 스트레스를 받을 수 있습니다. 둘째, 비정상적인 행동이나 소음이 발생할 수 있습니다. 셋째, 중성화하지 않은 암컷 고양이는 자궁축농증이나 유선종양과 같은 건강 문제에 걸릴 확률이 높습니다. 따라서 중성화를 고려하는 것이 고양이의 건강과 복지를 위해 좋습니다.\n",
    "출력: \n",
    "{{\n",
    "    \"facts in predicted answer\": \"1. 암컷 고양이를 중성화하지 않고 키우는 것은 여러 가지 위험을 동반할 수 있습니다. 2. 발정 주기가 반복되면서 스트레스를 받을 수 있습니다. 3. 비정상적인 행동이나 소음이 발생할 수 있습니다. 4. 중성화하지 않은 암컷 고양이는 자궁축농증이나 유선종양과 같은 건강 문제에 걸릴 확률이 높습니다. 5. 중성화를 고려하는 것이 고양이의 건강과 복지를 위해 좋습니다.\",\n",
    "    \"fact check predicted answer\": \"1. 암컷 고양이를 중성화하지 않고 키우는 것은 여러 가지 위험을 동반할 수 있습니다. 참조 답변에서 암컷 중성화의 필요성을 언급하며 생식기 질환 예방을 통해 이 사실을 뒷받침합니다. 2. 발정 주기가 반복되면서 스트레스를 받을 수 있습니다. 참조 답변에서 발정 주기로 인한 스트레스를 직접적으로 언급하지 않지만, 행동장애 예방과 성격순화에 도움이 된다는 점에서 간접적으로 관련됩니다. 충분한 정보 없음. 3. 비정상적인 행동이나 소음이 발생할 수 있습니다. 참조 답변에서 '행동장애'를 언급하며 이 사실을 뒷받침합니다. 4. 중성화하지 않은 암컷 고양이는 자궁축농증이나 유선종양과 같은 건강 문제에 걸릴 확률이 높습니다. 참조 답변에서 암컷의 유선종양, 자궁축농증, 난소종양 예방을 언급하며 이 사실을 뒷받침합니다. 5. 중성화를 고려하는 것이 고양이의 건강과 복지를 위해 좋습니다. 참조 답변에서 중성화 수술이 '생식기 질환을 예방할 수 있다'고 언급하여 이 사실을 뒷받침합니다.\",\n",
    "    \"facts count predicted answer\": 5,\n",
    "    \"support predicted answer\": 4,\n",
    "    \"facts in reference answer\": \"1. 강아지나 고양이는 수컷, 암컷 모두 중성화수술이 필요합니다. 2. 수컷 중성화는 행동장애, 전립선염, 전립선암, 항문선종과 같은 생식기 질환을 예방합니다. 3. 암컷 중성화는 생리, 유선종양, 자궁축농증, 난소종양과 같은 생식기 질환을 예방할 수 있습니다. 4. 생리불순인 상황에서는 중성화수술이 더욱 중요하며 위험성이 증가합니다. 5. 중성화수술은 가출 방지 및 성격 순화에도 도움이 됩니다. 6. 일반적으로 중성화수술은 생후 7개월 전후로 시행합니다.\",\n",
    "    \"fact check reference answer\": \"1. 강아지나 고양이는 수컷, 암컷 모두 중성화수술이 필요합니다. 예측 답변에서 암컷 고양이의 중성화가 '여러 가지 위험을 동반할 수 있다'며 중성화를 고려하는 것이 좋다고 언급하여 이 사실을 뒷받침합니다. 2. 수컷 중성화는 행동장애, 전립선염, 전립선암, 항문선종과 같은 생식기 질환을 예방합니다. 예측 답변은 암컷 고양이에 초점을 맞춰 수컷에 대한 언급이 없습니다. 충분한 정보 없음. 3. 암컷 중성화는 생리, 유선종양, 자궁축농증, 난소종양과 같은 생식기 질환을 예방할 수 있습니다. 예측 답변에서 '자궁축농증이나 유선종양과 같은 건강 문제에 걸릴 확률이 높다'고 언급하여 이 사실을 뒷받침합니다. 4. 생리불순인 상황에서는 중성화수술이 더욱 중요하며 위험성이 증가합니다. 예측 답변에서는 생리불순에 대한 직접적인 언급은 없습니다. 충분한 정보 없음. 5. 중성화수술은 가출 방지 및 성격 순화에도 도움이 됩니다. 예측 답변에서 '비정상적인 행동이나 소음이 발생할 수 있다'고 언급하여 이 사실과 간접적으로 관련됩니다. 충분한 정보 없음. 6. 일반적으로 중성화수술은 생후 7개월 전후로 시행합니다. 예측 답변에서는 중성화 시기에 대한 정보가 없습니다. 충분한 정보 없음.\",\n",
    "    \"facts count reference answer\": 6,\n",
    "    \"support reference answer\": 2\n",
    "}}\n",
    "\n",
    "### 입력:\n",
    "질문: {question}\n",
    "참조 답변: {ref_answer}\n",
    "예측 답변: {pred_answer}\n",
    "출력:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg input tokens: 3137개\n",
      "Avg output tokens: 843개\n",
      "Max input tokens: 4824개\n",
      "Max output tokens: 973개\n"
     ]
    }
   ],
   "source": [
    "input_tokens = []\n",
    "output_tokens = []\n",
    "\n",
    "input_path = \"/home/work/factchecking/PetQA/outputs/results/generated_answers/output_gpt-4o-mini_0_preprocessed.json\"\n",
    "with open(input_path, \"r\") as f:\n",
    "    input_data = json.load(f)\n",
    "    # input_data = input_data[:1000]\n",
    "    for item in input_data:\n",
    "        user_prompt = prompt.format(question=item[\"preprocessed_question\"], ref_answer=item[\"preprocessed_answer\"], pred_answer=item[\"generated_answer\"])\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ]\n",
    "        input_tokens.append(count_chat_tokens(messages))\n",
    "        \n",
    "output_path = \"/home/work/factchecking/PetQA/src/evaluation/response_results_exaone.json\"\n",
    "with open(output_path, \"r\") as f:\n",
    "    output_data = json.load(f)\n",
    "\n",
    "for item in output_data:\n",
    "    output_tokens.append(count_output_tokens(item))\n",
    "    \n",
    "avg_input_tokens = int(np.mean(input_tokens))\n",
    "avg_output_tokens = int(np.mean(output_tokens))\n",
    "max_input_tokens = int(np.max(input_tokens))\n",
    "max_output_tokens = int(np.max(output_tokens))\n",
    "\n",
    "print(f\"Avg input tokens: {avg_input_tokens}개\")\n",
    "print(f\"Avg output tokens: {avg_output_tokens}개\")\n",
    "print(f\"Max input tokens: {max_input_tokens}개\")\n",
    "print(f\"Max output tokens: {max_output_tokens}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "file_path = \"/home/work/factchecking/PetQA/outputs/results/generated_answers/output_exaone-3.5-7.8b_0_raw_ALL.json\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"/home/work/factchecking/PetQA/data/processed/test.json\"\n",
    "with open(file_path, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "q_ids_with_a_id = []\n",
    "duplication_count = 0\n",
    "for item in data:\n",
    "    q_id = item[\"q_id\"]\n",
    "    a_id = item[\"a_id\"]\n",
    "    if (q_id, a_id) in q_ids_with_a_id:\n",
    "        print(q_id)\n",
    "        duplication_count += 1\n",
    "    else:\n",
    "        new_item = (q_id, a_id)\n",
    "        q_ids_with_a_id.append(new_item)\n",
    "\n",
    "print(duplication_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "q_ids = []\n",
    "duplication_count = 0\n",
    "for item in data:\n",
    "    q_id = item[\"q_id\"]\n",
    "    if q_id in q_ids:\n",
    "        duplication_count += 1\n",
    "    else:\n",
    "        q_ids.append(q_id)\n",
    "\n",
    "print(duplication_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55393\n",
      "{'q_id': 61822, 'title': '강아지 발톱', 'content': '저희 강아지 발톱 중 한개가 반은 투명색, 반은 검정색잉에요놀라울 정도로 반반인데 괜찮은 건가요?털색은 검정 등, 배 쪽 흰 입니다..ㅜㅜ빠른 답변 부탁드려요내공 겁니다 정말 급해요', 'answer': '안녕하세요  발톱은 색소로 인해 색이 검을 수도 투명할 수도 있습니다. 아무 문제 없습니다.', 'a_id': 1, 'answer_type': 'nonexpert', 'question_date': '2022.08.10', 'answer_date': '2022.08.10.', 'animal_type': 'dog', 'preprocessed_question': '강아지 발톱 하나가 반은 투명색이고, 반은 검정색인데 괜찮은 건가요? 털색은 검정색이고 배 쪽은 흰색입니다.', 'preprocessed_answer': '발톱은 색소로 인해 색이 검을 수도 투명할 수도 있습니다. 아무 문제 없습니다.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "file_path = \"/home/work/factchecking/PetQA/data/interim/cleaned_data.json\"\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(len(data))\n",
    "print(data[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61825\n",
      "64129\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "file_path = \"/home/work/factchecking/PetQA/data/interim/unique_data.json\"\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    unique_data = json.load(f)\n",
    "\n",
    "print(len(unique_data))\n",
    "\n",
    "selected_cnt = 0\n",
    "for item in unique_data:\n",
    "    answers = item[\"answers\"]\n",
    "    for a in answers:\n",
    "        if a[\"selected\"]:\n",
    "            selected_cnt += 1\n",
    "print(selected_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering_all_results: 64129\n",
      "filtered_data: 56001\n",
      "irrelevant_data: 8128\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "filtering_all_results_path = \"/home/work/factchecking/PetQA/data/interim/filtering_all_results.json\"\n",
    "with open(filtering_all_results_path, 'r', encoding='utf-8') as f:\n",
    "    filtering_all_results = json.load(f)\n",
    "print(f\"filtering_all_results: {len(filtering_all_results)}\")\n",
    "\n",
    "filtered_data_path = \"/home/work/factchecking/PetQA/data/interim/filtered_data.json\"\n",
    "with open(filtered_data_path, 'r', encoding='utf-8') as f:\n",
    "    filtered_data = json.load(f)\n",
    "print(f\"filtered_data: {len(filtered_data)}\")\n",
    "\n",
    "irrelevant_data_path = \"/home/work/factchecking/PetQA/data/interim/irrelevant_data.json\"\n",
    "with open(irrelevant_data_path, 'r', encoding='utf-8') as f:\n",
    "    irrelevant_data = json.load(f)\n",
    "print(f\"irrelevant_data: {len(irrelevant_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복된 q_id 개수: 1635개\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "file_path = \"/home/work/factchecking/PetQA/data/interim/filtered_data.json\"\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "q_ids = [sample['q_id'] for sample in data if 'q_id' in sample]\n",
    "q_id_counter = Counter(q_ids)\n",
    "duplicate_q_ids = {qid: count for qid, count in q_id_counter.items() if count > 1}\n",
    "\n",
    "print(f\"중복된 q_id 개수: {len(duplicate_q_ids)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "암컷 고양이를 중성화하지 않고 키우는 것은 여러 가지 위험을 동반할 수 있습니다. 첫째, 발정 주기가 반복되면서 스트레스를 받을 수 있습니다. 둘째, 비정상적인 행동이나 소음이 발생할 수 있습니다. 셋째, 중성화하지 않은 암컷 고양이는 자궁축농증이나 유선종양과 같은 건강 문제에 걸릴 확률이 높습니다. 따라서 중성화를 고려하는 것이 고양이의 건강과 복지를 위해 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "당신은 반려동물(개, 고양이) 의료 상담 전문 수의사입니다.\n",
    "당신의 역할은 개, 고양이 관련 의료 질문에 대해 유용하고, 완전하며, 전문적인 지식에 기반한 정확한 답변을 하는 것입니다.\n",
    "질문에 대해 차근차근 생각하며 답변하고, 답변 문장의 개수는 최대 5개를 넘지 마세요.\n",
    "\"\"\"\n",
    "user_prompt = \"\"\"\n",
    "질문: 암컷 고양이를 키우고 있는데 중성화를 평생 안 하고 키워도 괜찮을까요?\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt}, \n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=512,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평가 과정을 설명하겠습니다. 주어진 질문과 수의사 답변, 그리고 모델의 답변을 바탕으로 두 가지 평가 기준인 completeness와 coherence를 각각 1점에서 5점 사이로 평가합니다.\n",
      "\n",
      "1. **completeness 평가 과정:**\n",
      "   - 질문에 대한 모델의 답변이 필요한 모든 정보를 포함하고 있는지 확인합니다.\n",
      "   - 답변이 질문과 관련이 있는지, 그리고 질문에 대해 충분히 답변하고 있는지를 평가합니다.\n",
      "   - 답변이 질문의 핵심을 잘 다루고 있는지, 중요한 정보가 빠져 있지는 않은지를 판단합니다.\n",
      "   - 이 기준에 따라 1점에서 5점 사이의 점수를 부여합니다.\n",
      "\n",
      "2. **coherence 평가 과정:**\n",
      "   - 모델의 답변 내 문장들이 논리적으로 잘 연결되어 있는지 확인합니다.\n",
      "   - 문장 간의 전환이 자연스러운지, 문맥이 매끄럽게 전개되는지를 평가합니다.\n",
      "   - 답변이 이해하기 쉬운지, 문장 구조가 명확한지를 판단합니다.\n",
      "   - 이 기준에 따라 1점에서 5점 사이의 점수를 부여합니다.\n",
      "\n",
      "각 기준에 대해 점수를 부여한 후, 그 이유를 간단히 설명하여 평가의 근거를 명확히 합니다. 이 과정에서 주어진 지침을 수시로 참조하여 일관된 평가를 유지합니다.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful and precise assistant for evaluating text generation.\"\n",
    "user_prompt = \"\"\"\n",
    "당신에게는 반려동물(개, 고양이) 의료 상담 관련 질문과 수의사 답변, 그리고 모델의 답변이 주어집니다.\n",
    "당신의 역할은 주어진 질문과 수의사 답변을 참고하여 모델의 답변을 다음 평가 기준에 따라 1점에서 5점 사이의 정수로 평가하는 것입니다.\n",
    "평가를 진행하기 전에 아래의 지침을 주의 깊게 읽고 이해했는지 반드시 확인하세요. 평가 중에도 수시로 이 지침을 참조하면서 일관되고 신중하게 판단해야 합니다.\n",
    "\n",
    "### 평가 기준:\n",
    "1. completeness\n",
    "- 정의: 질문에 답하기 위해 필요한 모든 필수 정보를 포함하고 있는 정도\n",
    "- 1: 질문과 무관한 내용만 포함하거나, 답변으로 간주할 수 없을 정도로 불완전함\n",
    "- 2: 핵심 내용이 거의 빠져 있거나 질문에 거의 답하지 못함\n",
    "- 3: 일부 중요한 정보가 빠져 있어 이해나 활용에 제한이 있음\n",
    "- 4: 대부분의 중요 정보를 포함하고 있으나, 약간의 보완이 필요할 수 있음\n",
    "- 5: 질문에 대한 답변이 충분하며, 모든 핵심 정보와 관련 세부사항이 포함됨\n",
    "\n",
    "2. coherence\n",
    "- 정의: 답변 내 문장 간 논리적 연결성과 문맥의 자연스러운 정도\n",
    "- 1: 문장이 거의 연결되지 않거나 비문 중심으로 구성되어 전혀 이해할 수 없음\n",
    "- 2: 전반적으로 논리 흐름이 거의 없고, 문장이 단절되거나 무작위적으로 배열됨\n",
    "- 3: 문장 간 논리 연결이 종종 끊기며, 문맥 전개에 혼란이 있음\n",
    "- 4: 대부분 자연스럽지만, 일부 문장 간 연결이 약하거나 어색한 전환이 있음\n",
    "- 5: 문장 간 논리적 흐름이 매우 자연스럽고, 전개가 매끄러움\n",
    "\n",
    "평가 과정을 설명하세요:\n",
    "\"\"\"\n",
    "# task introduction + evlauation criteria에 evaluation steps 추가하여 \n",
    "# auto CoT를 통해 평가 과정 생성\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}],\n",
    "    temperature=0\n",
    ")\n",
    "evaluation_steps = response.choices[0].message.content.strip()\n",
    "print(evaluation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini로 전처리 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "당신의 역할은 반려동물(개, 고양이) 의료 상담 관련 질문-답변 데이터셋을 구축하기 위해, 불필요한 문구를 제거하고 표현을 정제하는 것입니다.\n",
    "아래의 클리닝 방법을 참고하여 데이터를 클리닝하세요.\n",
    "최종적인 출력은 JSON 형식으로 출력하세요.\n",
    "\n",
    "### 클리닝 방법\n",
    "질문과 답변의 의미를 유지하면서 아래의 문구를 제거합니다. 이때 질문에서는 반려동물의 정보(종, 나이, 무게 등) 및 증상이 생략되지 않도록 하며, 답변에서는 진단 과정 및 치료 방법과 같은 중요한 정보가 생략되지 않도록 주의합니다.\n",
    "- 개인 정보 제거: 이름, 전화번호, 이메일, 주소 등 개인을 식별할 수 있는 정보 제거\n",
    "- 맞춤법 및 문법 수정: 문맥을 고려하여 올바른 맞춤법과 문법으로 교정\n",
    "- 구어체 수정: 공식적인 질문과 답변 형식에 맞게 문어체로 변환\n",
    "- 의미 전달에 필요하지 않은 감정 표현 제거 (예: 강아지의 이상 행동에 대해 걱정이 많으시죠?, 고양이의 이상 증상에 대해 걱정이 많으시죠? 등)\n",
    "- 인사 문구 제거 (예: 안녕하세요, 감사합니다 등)\n",
    "- 광고나 홍보 문구 제거 (예: 추가 상담을 원하시면 아래 링크를 클릭해주세요)\n",
    "- 그 외 질문과 답변에 필요없는 불필요한 문구 제거 (예: 질문 잘 읽었습니다. 등)\n",
    "\"\"\"\n",
    "user_prompt = \"\"\"\n",
    "질문 제목: 고양이 결막염 증상 중에\n",
    "질문 본문: 고양이가 눈은 제대로 뜨지 못해 병원에 갔더니 결막염 처방을 받아 꼬박꼬박 안약을 잘 넣어 주고 있습니다. 그런데 고양이 눈이 다른 한쪽 눈에 비해 뿌옇게 흐려졌어요.인터넷을 찾아보니 이거는 각막궤양의 증상이라고 하더라고요. 혹시 결막염 증상 중에 이런 증상이 있나요??아니면 다시 병원에 방문해서 검사를 받아봐야 할까요??ㅠㅠ\n",
    "답변: 안녕하세요? 지식iN 동물의료상담 활동을 하고 있는 수의사 윤성진 입니다. 눈때문에 걱정이 많으시겠어요. 각막이 뿌옇게 흐려졌다고 해서 각막궤양이라고 할 수는 없습니다. 결막염이 심했다면 각막염이나 각막부종이 동반된 경우 일수도 있고, 각막궤양이 잇어서 눈을 제대로 뜨지 못했을 가능성도 있습니다. 병원에 내원하셔서 제대로 안검사를 받아보시는 것이 좋겠습니다. 형광염색검사로 각막궤양이 있는지도 확인할 필요가 있습니다. 빠른 쾌유 바랍니다.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"preprocessed_question\": \"고양이가 결막염으로 안약을 투여 중인데, 한쪽 눈이 뿌옇게 흐려졌습니다. 인터넷에서 각막궤양 증상이라고 하는데, 결막염 증상으로도 나타날 수 있나요? 아니면 병원에 다시 방문해야 할까요?\",\n",
      "    \"preprocessed_answer\": \"각막이 뿌옇게 흐려졌다고 해서 각막궤양이라고 단정할 수는 없습니다. 결막염이 심한 경우 각막염이나 각막부종이 동반될 수 있고, 각막궤양이 있어 눈을 제대로 뜨지 못했을 가능성도 있습니다. 병원에 내원하여 안검사를 받아보시고, 형광염색검사로 각막궤양 여부를 확인하는 것이 좋겠습니다.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "class Preprocess(BaseModel):\n",
    "    preprocessed_question: str\n",
    "    preprocessed_answer: str\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=user_prompt,\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction = system_prompt,\n",
    "        temperature=0,\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=Preprocess\n",
    "    ),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Batch API 테스트 (실패)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import fsspec\n",
    "from google import genai\n",
    "# from google.cloud import bigquery\n",
    "from google.genai.types import CreateBatchJobConfig\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asia-northeast3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "PROJECT_ID = \"petqa-463515\"\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\")\n",
    "print(LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n",
    "MODEL_ID = \"gemini-2.0-flash-001\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def create_jsonl_file(output_filename: str, requests: list[dict]):\n",
    "    try:\n",
    "        with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "            for req in requests:\n",
    "                # 각 요청 딕셔너리를 JSON 문자열로 변환하고 새 줄에 작성합니다.\n",
    "                json_line = json.dumps(req, ensure_ascii=False)\n",
    "                f.write(json_line + '\\n')\n",
    "        print(f\"'{output_filename}' 파일이 성공적으로 생성되었습니다.\")\n",
    "    except IOError as e:\n",
    "        print(f\"파일 작성 중 오류가 발생했습니다: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"예상치 못한 오류가 발생했습니다: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    batch_requests = [\n",
    "        {\n",
    "            \"request\": {\n",
    "                \"contents\": [\n",
    "                    {\"role\": \"user\", \"parts\": [{\"text\": \"다음 동영상과 이미지 샘플의 관계는 무엇입니까?\"}]},\n",
    "                    {\"fileData\": {\"fileUri\": \"gs://cloud-samples-data/generative-ai/video/animals.mp4\", \"mimeType\": \"video/mp4\"}},\n",
    "                    {\"fileData\": {\"fileUri\": \"gs://cloud-samples-data/generative-ai/image/cricket.jpeg\", \"mimeType\": \"image/jpeg\"}}\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"request\": {\n",
    "                \"contents\": [\n",
    "                    {\"role\": \"user\", \"parts\": [{\"text\": \"이 동영상에서 무슨 일이 일어나고 있는지 설명해 주세요.\"}]},\n",
    "                    {\"fileData\": {\"fileUri\": \"gs://cloud-samples-data/generative-ai/video/another_video.mov\", \"mimeType\": \"video/mov\"}}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # JSONL 파일 생성 함수를 호출합니다.\n",
    "    output_file = \"batch_input.jsonl\"\n",
    "    create_jsonl_file(output_file, batch_requests)\n",
    "\n",
    "    # 생성된 파일의 내용을 확인 (선택 사항)\n",
    "    print(\"\\n--- 생성된 파일 내용 확인 ---\")\n",
    "    try:\n",
    "        with open(output_file, 'r', encoding='utf-8') as f:\n",
    "            for line_num, line in enumerate(f, 1):\n",
    "                print(f\"라인 {line_num}: {line.strip()}\")\n",
    "                # 각 라인이 유효한 JSON인지 확인 (선택 사항)\n",
    "                try:\n",
    "                    json.loads(line)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"경고: 라인 {line_num}은 유효한 JSON이 아닙니다: {e}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"'{output_file}' 파일을 찾을 수 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 토큰 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 모델: gemini-2.0-flash\n",
      "필터링 비용: $3.32\n",
      "클리닝 비용: $16.53\n",
      "------------------------------\n",
      "답변 생성 비용 (batch API 사용 시)\n",
      "gpt-4o-mini-0: $1.16\n",
      "gpt-4o-mini-1: $1.61\n",
      "gpt-4o-mini-3: $2.53\n",
      "gpt-4o-mini-6: $3.92\n",
      "------------------------------\n",
      "claude-3-haiku-0: $4.02\n",
      "claude-3-haiku-1: $5.26\n",
      "claude-3-haiku-3: $7.81\n",
      "claude-3-haiku-6: $11.63\n",
      "------------------------------\n",
      "gemini-2.0-flash-0: $0.72\n",
      "gemini-2.0-flash-1: $1.00\n",
      "gemini-2.0-flash-3: $1.56\n",
      "gemini-2.0-flash-6: $2.41\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------\n",
    "MODEL_PRICE = {\n",
    "    'gpt-4o-mini': {\"input_token\": 0.15, \"output_token\": 0.60},\n",
    "    'claude-3-haiku': {\"input_token\": 0.25, \"output_token\": 1.25},\n",
    "    'gemini-2.0-flash': {\"input_token\": 0.1, \"output_token\": 0.4},\n",
    "}\n",
    "\n",
    "\"\"\" 전처리 시(필터링, 클리닝), 모델별 입력 토큰 사용량\"\"\"\n",
    "avg_input_token_F = {\n",
    "    \"gpt-4o-mini\": 558,\n",
    "    \"gemini-2.0-flash\": 513 \n",
    "}\n",
    "\n",
    "avg_output_token_F = {\n",
    "    \"gpt-4o-mini\": 1,\n",
    "    \"gemini-2.0-flash\": 1,\n",
    "}\n",
    "\n",
    "avg_input_token_C = {\n",
    "    \"gpt-4o-mini\": 695,\n",
    "    \"gemini-2.0-flash\": 644,\n",
    "}\n",
    "\n",
    "avg_output_token_C = {\n",
    "    \"gpt-4o-mini\": 218,\n",
    "    \"gemini-2.0-flash\": 577,\n",
    "}\n",
    "\n",
    "\"\"\" 답변 생성 시, 모델별 입력 토큰 사용량\n",
    "- gpt-4o-mini: 약 300 토큰\n",
    "- claude-3-haiku: 약 500 토큰\n",
    "- gemini-2.0-flash: 약 280 토큰\n",
    "\"\"\"\n",
    "avg_input_token_A = {\n",
    "    \"0\": {\"gpt-4o-mini\": 265, \"claude-3-haiku\": 417, \"gemini-2.0-flash\": 231},\n",
    "    \"1\": {\"gpt-4o-mini\": 567, \"claude-3-haiku\": 916, \"gemini-2.0-flash\": 510},\n",
    "    \"3\": {\"gpt-4o-mini\": 1181, \"claude-3-haiku\": 1933, \"gemini-2.0-flash\": 1074},\n",
    "    \"6\": {\"gpt-4o-mini\": 2106, \"claude-3-haiku\": 3464, \"gemini-2.0-flash\": 1925},\n",
    "}\n",
    "\"\"\" 답변 생성 시, 모델별 출력 토큰 사용량\"\"\"\n",
    "avg_output_token_A = {\n",
    "    \"gpt-4o-mini\": 127,\n",
    "    \"claude-3-haiku\": 238,\n",
    "    \"gemini-2.0-flash\": 122,\n",
    "}\n",
    "\n",
    "# ------------------------------------------\n",
    "PREPROCESS_MODEL = \"gemini-2.0-flash\"\n",
    "MILLION_TOKEN = 1000000\n",
    "\n",
    "FILTERING_SIZE = 64129\n",
    "CLEANING_SIZE = 56001\n",
    "TEST_SIZE = 10000\n",
    "# ------------------------------------------\n",
    "print(f\"전처리 모델: {PREPROCESS_MODEL}\")\n",
    "# ------------------------------------------\n",
    "filtering_cost = MODEL_PRICE[PREPROCESS_MODEL][\"input_token\"] * avg_input_token_F[PREPROCESS_MODEL]+ MODEL_PRICE[PREPROCESS_MODEL][\"output_token\"] * avg_output_token_F[PREPROCESS_MODEL]\n",
    "filtering_cost = (filtering_cost * FILTERING_SIZE) / MILLION_TOKEN\n",
    "print(f\"필터링 비용: ${filtering_cost:.2f}\")\n",
    "# ------------------------------------------\n",
    "cleaning_cost = MODEL_PRICE[PREPROCESS_MODEL][\"input_token\"] * avg_input_token_C[PREPROCESS_MODEL] + MODEL_PRICE[PREPROCESS_MODEL][\"output_token\"] * avg_output_token_C[PREPROCESS_MODEL]\n",
    "cleaning_cost = (cleaning_cost * CLEANING_SIZE) / MILLION_TOKEN\n",
    "print(f\"클리닝 비용: ${cleaning_cost:.2f}\")\n",
    "print(\"---\"*10)\n",
    "# ------------------------------------------\n",
    "print(\"답변 생성 비용 (batch API 사용 시)\")\n",
    "for model_name, price in MODEL_PRICE.items():\n",
    "    for shot, input_token_dict in avg_input_token_A.items():\n",
    "        answering_cost = price[\"input_token\"] * input_token_dict[model_name] + price[\"output_token\"] * avg_output_token_A[model_name]\n",
    "        answering_cost = (answering_cost * TEST_SIZE) / MILLION_TOKEN  # 입력 형식 고려\n",
    "        print(f\"{model_name}-{shot}: ${answering_cost:.2f}\")\n",
    "    print(\"---\"*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import anthropic\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'q_id': 22264,\n",
       " 'title': '강아지 슬개골 탈구 수술 꼭 해야 하나요?',\n",
       " 'content': '2살 된 비숑이고 오늘 한쪽 2기 한쪽 3기 진단 받았습니다문제되는 3기 다리를 병원에서는 수술 권유를 하는데찾아보니 일상생활을 지내는 데에 심하게 아파하지 않으면 케어만 신경써서 해줘도 된다는 의견들이 있으시더라구요 ㅠ평소에는 놀기도 잘 놀고 먹고 잘 걸어다니는데 높은 곳 (침대에서 바닥)으로 뛰어 내릴때 문제되는 3기 다리를 깽깽이? 한발 들고 다녔다가 시간이 경과한 후엔 또 정상적으로 잘 걸어 다녀요 ㅠㅠ수술 비용도 만만치 않고전신마취가 강아지한텐 좋지 않다 들어서 고민중입니다수술 무조건 해야 할까요?수술을 해도 재발하거나 수술후에 증상이 호전되지 않아서 다시 수술 부위를 여는데도 많다 해서 ㅠ조언 부탁드립니다!!',\n",
       " 'answers': [{'a_id': 0,\n",
       "   'answer_type': 'nonexpert',\n",
       "   'answer': '안녕하세요. \"동물의료상담 지식인\"에 선정된 부천 중동 \"하모니동물병원\" 원장입니다. \\u200b 슬개골탈구 교정술은 해줘야 하지만 선택은 보호자 몫이며 수술시 마취는,  사전검사에 의해서 안전성이 크게 확보됩니다. \\u200b 현재 2년령이면 앞으로 13~17년 정도는 더 살아야 천수를 다하는데 슬개골탈구를 수술치 않고 방치하면  4기 말기쯤에선 상당히 괴로워하며 심하면 다리를 못쓰게 되기도 합니다. \\u200b 3기에서도 뛰어내릴 때 통증이 심해 깽깽이 발처럼 한발을 드는데 더욱 심화될 경우는 어떠하겠습니까? \\u200b 모쪼록 현명한 선택으로, 좋은 결과만 얻으시길 기원합니다. \\u200b 사이버 답변이지만 조금이라도 도움됐으면 좋겠습니다. \\u200b ***** cafe.naver.com/harmonyhospital \\u200b \\u200b',\n",
       "   'selected': True,\n",
       "   'answer_date': '2022.10.15.'}],\n",
       " 'question_date': '2022.10.15',\n",
       " 'animal_type': 'dog',\n",
       " 'link': 'https://kin.naver.com/qna/detail.naver?d1id=8&dirId=80511&docId=430550950&qb=6rCV7JWE7KeA&enc=utf8&section=kin.qna_ency&rank=460&search_sort=3&spq=0'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_path = \"/home/work/factchecking/PetQA/data/interim/unique_data.json\"\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "random.seed(42)\n",
    "data = random.sample(data, 1000)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_token_counts(results):\n",
    "    input_tokens = [r[\"input_tokens\"] for r in results]\n",
    "    output_tokens = [r[\"output_tokens\"] for r in results]\n",
    "    avg_input_tokens = int(np.mean(input_tokens))\n",
    "    avg_output_tokens = int(np.mean(output_tokens))\n",
    "    print(f\"Avg input tokens: {avg_input_tokens}개\")\n",
    "    print(f\"Avg output tokens: {avg_output_tokens}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtering_system_prompt = \"\"\"\n",
    "당신의 역할은 반려동물(개, 고양이) 의료 상담 관련 질문-답변 데이터셋을 구축하기 위해, 관련 없는 데이터를 필터링하는 것입니다.\n",
    "아래의 필터링 기준을 참고하여 관련 없는 데이터를 필터링하세요.\n",
    "최종적인 출력은 반드시 True 또는 False를 출력하세요. 그 외 다른 텍스트를 포함하지 마세요.\n",
    "\n",
    "### 필터링 기준\n",
    "다음 조건 중 하나라도 해당될 경우 False를 반환합니다.\n",
    "- 개인정보 노출 또는 서비스 운영 원칙에 위배된 내용이 포함된 질문\n",
    "- 반려동물(개, 고양이) 의료 상담과 관련 없는 질문\n",
    "- 질문 해결 실패: 질문이 충분히 구체적이고 명확하지 않아 답변을 하기 위해 추가적인 설명이 필요한 경우 (예: \"설명하신 내용만으로 어떤 상황인지 알 수 없습니다.\" 등)\n",
    "- 근거 없이 추측성으로 작성된 답변\n",
    "- 단순히 \"병원에 가보세요\"와 같이 정보적 가치가 거의 없는 답변\n",
    "\n",
    "위 조건에 모두 해당하지 않는 경우에는 True를 반환합니다.\n",
    "\"\"\"\n",
    "\n",
    "base_user_prompt = \"\"\"\n",
    "질문 제목: {title}\n",
    "질문 본문: {content}\n",
    "답변: {answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "encoding = tiktoken.encoding_for_model('gpt-4o-mini')\n",
    "print(len(encoding.encode(\"hello\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg input tokens: 558개\n",
      "Avg output tokens: 1개\n"
     ]
    }
   ],
   "source": [
    "def count_chat_tokens(messages):\n",
    "    encoding = tiktoken.encoding_for_model('gpt-4o-mini')\n",
    "    tokens_per_message = 3  # role + content + 구조적 오버헤드\n",
    "    tokens_per_name = 1     # name 필드\n",
    "\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # assistant 응답 시작 오버헤드\n",
    "    return num_tokens\n",
    "\n",
    "def count_output_tokens(output_text):\n",
    "    encoding = tiktoken.encoding_for_model('gpt-4o-mini')\n",
    "    return len(encoding.encode(output_text))\n",
    "\n",
    "results = []\n",
    "for sample in data:\n",
    "    title = sample['title']\n",
    "    content = sample.get('content', '')\n",
    "    answers = sample['answers']\n",
    "    \n",
    "    for a in answers:\n",
    "        if a['selected']:\n",
    "            user_prompt = base_user_prompt.format(title=title, content=content, answer=a['answer'])\n",
    "        \n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": filtering_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "\n",
    "            input_tokens = count_chat_tokens(messages)\n",
    "            results.append({\n",
    "                \"input_tokens\": input_tokens,\n",
    "                \"output_tokens\": 1\n",
    "            })\n",
    "\n",
    "avg_token_counts(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gemini-2.0-flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg input tokens: 513개\n",
      "Avg output tokens: 1개\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for sample in data:\n",
    "    title = sample['title']\n",
    "    content = sample.get('content', '')\n",
    "    answers = sample['answers']\n",
    "    \n",
    "    for a in answers:\n",
    "        if a['selected']:\n",
    "            user_prompt = base_user_prompt.format(title=title, content=content, answer=a['answer'])\n",
    "    \n",
    "            model = genai.GenerativeModel(\n",
    "                model_name='gemini-2.0-flash-001',\n",
    "                system_instruction=filtering_system_prompt\n",
    "            )\n",
    "            input_tokens = model.count_tokens(user_prompt).total_tokens\n",
    "    \n",
    "            results.append({\n",
    "                \"input_tokens\": input_tokens,\n",
    "                \"output_tokens\": 1\n",
    "            })\n",
    "\n",
    "avg_token_counts(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = \"/home/work/factchecking/PetQA/data/interim/unique_data.json\"\n",
    "with open(raw_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "random.seed(42)\n",
    "data = random.sample(data, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_system_prompt = \"\"\"\n",
    "당신의 역할은 반려동물(개, 고양이) 의료 상담 관련 질문-답변 데이터셋을 구축하기 위해, 불필요한 문구를 제거하고 표현을 정제하는 것입니다.\n",
    "아래의 클리닝 방법을 참고하여 데이터를 클리닝하세요.\n",
    "출력 형식은 반드시 아래의 JSON 형식에 따라 출력하세요. 그 외 다른 텍스트를 포함하지 마세요.\n",
    "\n",
    "### 클리닝 방법\n",
    "질문과 답변의 의미를 유지하면서 아래의 문구를 제거합니다. 이때 질문에서는 반려동물의 정보(종, 나이, 무게 등) 및 증상이 생략되지 않도록 하며, 답변에서는 진단 과정 및 치료 방법과 같은 중요한 정보가 생략되지 않도록 주의합니다.\n",
    "- 개인 정보 제거: 이름, 전화번호, 이메일, 주소 등 개인을 식별할 수 있는 정보 제거\n",
    "- 맞춤법 및 문법 수정: 문맥을 고려하여 올바른 맞춤법과 문법으로 교정\n",
    "- 구어체 수정: 공식적인 질문과 답변 형식에 맞게 문어체로 변환\n",
    "- 의미 전달에 필요하지 않은 감정 표현 제거 (예: 강아지의 이상 행동에 대해 걱정이 많으시죠?, 고양이의 이상 증상에 대해 걱정이 많으시죠? 등)\n",
    "- 인사 문구 제거 (예: 안녕하세요, 감사합니다 등)\n",
    "- 광고나 홍보 문구 제거 (예: 추가 상담을 원하시면 아래 링크를 클릭해주세요)\n",
    "- 그 외 질문과 답변에 필요없는 불필요한 문구 제거 (예: 질문 잘 읽었습니다. 등)\n",
    "\n",
    "### 출력 형식\n",
    "{\n",
    "    \"preprocessed_question\": \"\",\n",
    "    \"preprocessed_answers\": \"\"\n",
    "}  \n",
    "\"\"\"\n",
    "def remove_common_greetings(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    \n",
    "    # 유니코드 특수문자(제로폭 공백 등) 제거\n",
    "    text = re.sub(r'[\\u200b\\u200c\\u200d\\u2060\\ufeff]', '', text)\n",
    "    \n",
    "    patterns = [\n",
    "        # 시작 문구\n",
    "        r'^안녕하세요.*?입니다\\.?\\s*',\n",
    "        \n",
    "        # 끝 문구\n",
    "        r'\\s*감사합니다\\.?\\s*$',\n",
    "        r'\\s*고맙습니다\\.?\\s*$',\n",
    "        r'\\s*안녕히\\s*계세요\\.?\\s*$',\n",
    "        r'\\s*안녕히\\s*가세요\\.?\\s*$',\n",
    "        r'\\s*수고하세요\\.?\\s*$',\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        text = re.sub(pattern, '', text, flags=re.MULTILINE | re.UNICODE).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg input tokens: 695개\n",
      "Avg output tokens: 218개\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for sample in data:\n",
    "    title = sample['title']\n",
    "    content = sample['content']\n",
    "    answers = sample['answers']\n",
    "    for a in answers:\n",
    "        if a['selected']:\n",
    "            user_prompt = base_user_prompt.format(title=title, content=content, answer=remove_common_greetings(a['answer'])\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": cleaning_system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ]\n",
    "            output_text = '''\n",
    "            {\n",
    "                \"preprocessed_question\": \"고양이가 오늘 낮부터 구토를 하고 있습니다. 사료가 섞인 구토를 하다가 방금은 하얀 토를 했습니다. 지금 밥도 먹지 않고 물도 잘 안 마시는 것 같습니다. 평소에는 활달했는데 오늘은 계속 혼자 있습니다. 지금까지 6번 정도 구토를 한 것 같고, 물도 먹지 않아 탈수증이 걱정됩니다. 많이 위험한 것은 아니겠죠? 지금도 계속 힘없이 누워 있습니다.\", \n",
    "                \"preprocessed_answer\": \"고양이가 구토를 한다면 병원에 내원하여 구토를 일으킬 만한 가능한 원인을 찾고 대증치료를 받는 것이 좋습니다. 구토가 계속되면 식욕부진이나 탈수가 발생하고, 이로 인해 신장이나 췌장 손상 또는 고양이 지방간이 발생할 수 있으므로 적극적인 처치를 받는 것이 필요합니다.\"\n",
    "            }\n",
    "            '''\n",
    "\n",
    "            input_tokens = count_chat_tokens(messages)\n",
    "            output_tokens = count_output_tokens(output_text)\n",
    "            results.append({\n",
    "                \"input_tokens\": input_tokens,\n",
    "                \"output_tokens\": output_tokens\n",
    "            })\n",
    "    \n",
    "avg_token_counts(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gemini-2.0-flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg input tokens: 644개\n",
      "Avg output tokens: 577개\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for sample in data:\n",
    "    title = sample['title']\n",
    "    content = sample.get('content', '')\n",
    "    answers = sample['answers']\n",
    "    \n",
    "    for a in answers:\n",
    "        if a['selected']:\n",
    "            model = genai.GenerativeModel(\n",
    "                model_name='gemini-2.0-flash-001',\n",
    "                system_instruction=cleaning_system_prompt\n",
    "            )\n",
    "            user_prompt = base_user_prompt.format(title=title, content=content, answer=remove_common_greetings(a['answer']))\n",
    "            output_text = '''\n",
    "            {\n",
    "                \"preprocessed_question\": \"고양이가 오늘 낮부터 구토를 하고 있습니다. 사료가 섞인 구토를 하다가 방금은 하얀 토를 했습니다. 지금 밥도 먹지 않고 물도 잘 안 마시는 것 같습니다. 평소에는 활달했는데 오늘은 계속 혼자 있습니다. 지금까지 6번 정도 구토를 한 것 같고, 물도 먹지 않아 탈수증이 걱정됩니다. 많이 위험한 것은 아니겠죠? 지금도 계속 힘없이 누워 있습니다.\", \n",
    "                \"preprocessed_answer\": \"고양이가 구토를 한다면 병원에 내원하여 구토를 일으킬 만한 가능한 원인을 찾고 대증치료를 받는 것이 좋습니다. 구토가 계속되면 식욕부진이나 탈수가 발생하고, 이로 인해 신장이나 췌장 손상 또는 고양이 지방간이 발생할 수 있으므로 적극적인 처치를 받는 것이 필요합니다.\"\n",
    "            }\n",
    "            '''\n",
    "            \n",
    "            input_tokens = model.count_tokens(user_prompt).total_tokens\n",
    "            output_tokens = model.count_tokens(output_text).total_tokens\n",
    "            results.append({\n",
    "                \"input_tokens\": input_tokens,\n",
    "                \"output_tokens\": output_tokens\n",
    "            })\n",
    "\n",
    "avg_token_counts(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 답변 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "open LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "\n",
    "df = pd.read_json(\"test_data/output_gpt-4o-mini.json\")\n",
    "system_prompt = \"\"\"\n",
    "당신은 반려동물(개, 고양이) 의료 상담 전문 수의사입니다.\n",
    "당신의 역할은 개, 고양이 관련 의료 질문에 대해 유용하고, 완전하며, 전문적인 지식에 기반한 정확한 답변을 하는 것입니다.\n",
    "질문에 대해 차근차근 생각하며 답변하고, 답변 문장의 개수는 최대 5개를 넘지 마세요.\n",
    "\"\"\"\n",
    "base_user_prompt = \"\"\"\n",
    "제목: {title}\n",
    "본문: {content}\n",
    "답변:  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468bd9bac5574e429f1de0e738581efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemma-3-4b: 1342\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0adb8ef1077b4531b897b8a9803b897c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwen-2.5-7b: 1685\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78c80f769804c738ebbc78b09fd46c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exaone-3.5-7.8b: 1197\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "MODEL_MAPPING = {\n",
    "    \"gemma-3-4b\": \"google/gemma-3-4b-it\",\n",
    "    \"qwen-2.5-7b\": \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "    \"exaone-3.5-7.8b\": \"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\",\n",
    "}\n",
    "model_names = [\n",
    "    'gemma-3-4b',\n",
    "    'qwen-2.5-7b',\n",
    "    'exaone-3.5-7.8b',\n",
    "]\n",
    "\n",
    "for model_name in model_names:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_MAPPING[model_name],\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        MODEL_MAPPING[model_name],\n",
    "    )\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    results = []\n",
    "    for idx, row in df.iterrows():\n",
    "        user_prompt = base_user_prompt.format(\n",
    "            title=row['title'],\n",
    "            content=row['content']\n",
    "        )\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "            {\"role\": \"assistant\", \"content\": row['preprocessed_answer']}\n",
    "        ]\n",
    "        \n",
    "        prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "        \n",
    "        tokens = tokenizer.encode(prompt, add_special_tokens=True)\n",
    "        \n",
    "        results.append(len(tokens))\n",
    "    \n",
    "    print(f\"{model_name}: {int(np.max(results))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"test_data/output_gpt-4o-mini.json\")\n",
    "fewshot_df = pd.read_json(\"test_data/fewshot_examples.json\")\n",
    "fewshot_map = {row[\"id\"]: row for _, row in fewshot_df.iterrows()}\n",
    "def build_fewshot_examples(sample):\n",
    "    examples = \"\"\n",
    "    for i in range(3):\n",
    "        title = sample[\"similar_questions\"][i][\"title\"]\n",
    "        content = sample[\"similar_questions\"][i][\"content\"]\n",
    "        answer = sample[\"similar_questions\"][i][\"preprocessed_answer\"]\n",
    "        examples += f\"제목: {title}\\n본문: {content}\\n답변: {answer}\\n\\n\"\n",
    "    return examples.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 13851,\n",
       " 'title': '치와와털이 탈모처럼 빠져요',\n",
       " 'content': '약4개월된 단모치와와키우고있는데요~ 허벅지쪽이랑 머리쪽이 특히 양쪽허벅지쪽털이 듬성듬성 탈모처럼빠지는데 이게 먼증상인가요. 동물병원 2주전갔을땐 이보단덜했는데 피부병은아니라고 곰팡이성질환일수있으니 약용샴푸써보라해서 3번정도썼거든요~ 털이너무 듬성빠져서 걱정되서요백신은 종합5차와 코로나 남은상화이구 몸무게닌 약1.2 키로일거같아요',\n",
       " 'answer': '어린 강아지인데 걱정이 많으시겠습니다. 곰팡이성질환도 피부병의 한 종류입니다. 약용샴푸로 곰팡이성 피부병이 치료될 수도 있으나 털이 듬성 듬성 더 빠지고 \\xa0심해졌다면 내복약 처방이 필요할 수 도있습니다. 곰팡이성 피부염은 보호자에게도 전염될 수 있기 때문에 반드시 병원에서 치료를 받으시길 추천합니다.',\n",
       " 'preprocessed_question': '약 4개월 된 단모 치와와를 키우고 있는데 허벅지와 머리 쪽 털이 듬성듬성 빠지는데 이게 무슨 증상인가요? 2주 전 동물병원에서는 피부병은 아니라고 했고 곰팡이성 질환일 수 있으니 약용 샴푸를 써보라고 해서 3번 정도 사용했습니다. 털이 너무 빠져서 걱정됩니다. 백신은 종합 5차와 코로나 남은 상태이며 몸무게는 약 1.2kg일 것 같습니다.',\n",
       " 'preprocessed_answer': '어린 강아지의 경우 곰팡이성 질환도 피부병의 한 종류입니다. 약용 샴푸로 곰팡이성 피부병이 치료될 수 있으나, 털이 더 많이 빠지고 악화되었다면 내복약 처방이 필요할 수 있습니다. 곰팡이성 피부염은 보호자에게도 전염될 수 있으니 반드시 병원에서 치료를 받으실 것을 권장합니다.',\n",
       " 'answer_date': '2014.10.22.',\n",
       " 'generated_answer': '4개월 된 치와와의 털 빠짐은 여러 원인으로 발생할 수 있습니다.\\n피부병이 아니라고 하셨다면, 알레르기 반응이나 스트레스, 영양 부족 등이 원인일 수 있습니다.\\n약용 샴푸를 사용한 후에도 개선되지 않는다면, 추가적인 검사가 필요할 수 있습니다.\\n특히, 영양 상태를 점검하고, 알레르기 검사를 고려해보는 것이 좋습니다.\\n정확한 진단을 위해 수의사와의 상담을 지속하시길 권장합니다.'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"/home/work/factchecking/PetQA/outputs/results/generated_answers/output_gpt-4o-mini_0_preprocessed.json\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "random.seed(42)\n",
    "data = random.sample(data, 1000)\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_system_prompt = \"\"\"\n",
    "당신은 반려동물(개, 고양이) 의료 상담 전문 수의사입니다.\n",
    "당신의 역할은 개, 고양이 관련 의료 질문에 대해 유용하고, 완전하며, 전문적인 지식에 기반한 정확한 답변을 하는 것입니다.\n",
    "질문에 대해 차근차근 생각하며 답변하고, 답변 문장의 개수는 최대 5개를 넘지 마세요.\n",
    "\"\"\"\n",
    "\n",
    "base_user_prompt = \"\"\"\n",
    "제목: {title}\n",
    "본문: {content}\n",
    "답변:  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg input tokens: 269개\n",
      "Avg output tokens: 127개\n"
     ]
    }
   ],
   "source": [
    "model = 'gpt-4o-mini'\n",
    "results = []\n",
    "for sample in data:\n",
    "    # sample = fewshot_map.get(row[\"id\"])\n",
    "    # fewshot_examples = build_fewshot_examples(sample)\n",
    "    # system_prompt = base_system_prompt.format(fewshot_examples=fewshot_examples)\n",
    "    system_prompt = base_system_prompt\n",
    "    user_prompt = base_user_prompt.format(title=sample['title'], content=sample['content'])\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "    output_text = sample['generated_answer']\n",
    "\n",
    "    input_tokens = count_chat_tokens(messages)\n",
    "    output_tokens = count_output_tokens(output_text)\n",
    "    results.append({\n",
    "        \"input_tokens\": input_tokens,\n",
    "        \"output_tokens\": output_tokens\n",
    "    })\n",
    "    \n",
    "avg_token_counts(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "claude-3-haiku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg input tokens: 620개\n",
      "Avg output tokens: 0개\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = []\n",
    "for item in data:\n",
    "    # sample = fewshot_map.get(row[\"id\"])\n",
    "    # fewshot_examples = build_fewshot_examples(sample)\n",
    "    # system_prompt = base_system_prompt.format(fewshot_examples=fewshot_examples)\n",
    "    system_prompt = base_system_prompt\n",
    "    user_prompt = base_user_prompt.format(title=sample['title'], content=sample['content'])\n",
    "    \n",
    "    input_response = client.messages.count_tokens(\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        system = system_prompt,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    # output_response = client.messages.count_tokens(\n",
    "    #     model=\"claude-3-haiku-20240307\",\n",
    "    #     messages=[\n",
    "    #         {\"role\": \"user\", \"content\": row['generated_answer']},\n",
    "    #     ],\n",
    "    # )\n",
    "    \n",
    "    input_tokens = input_response.input_tokens\n",
    "    # output_tokens = output_response.input_tokens\n",
    "    output_tokens = 0\n",
    "    results.append({\n",
    "        \"input_tokens\": input_tokens,\n",
    "        \"output_tokens\": output_tokens,\n",
    "    })\n",
    "    \n",
    "avg_token_counts(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gemini-2.0-flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg input tokens: 235개\n",
      "Avg output tokens: 0개\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for sample in data:\n",
    "    # sample = fewshot_map.get(row[\"id\"])\n",
    "    # fewshot_examples = build_fewshot_examples(sample)\n",
    "    # system_prompt = base_system_prompt.format(fewshot_examples=fewshot_examples)\n",
    "    system_prompt = base_system_prompt\n",
    "    user_prompt = base_user_prompt.format(title=sample['title'], content=sample['content'])\n",
    "    \n",
    "    model = genai.GenerativeModel(\n",
    "        model_name='gemini-2.0-flash-001',\n",
    "        system_instruction=system_prompt\n",
    "    )\n",
    "    input_tokens = model.count_tokens(user_prompt).total_tokens\n",
    "    \n",
    "    # model = genai.GenerativeModel(\n",
    "    #     model_name='gemini-2.0-flash-001',\n",
    "    # )\n",
    "    # output_tokens = model.count_tokens(row['generated_answer']).total_tokens\n",
    "    output_tokens = 0\n",
    "    \n",
    "    results.append({\n",
    "        \"input_tokens\": input_tokens,\n",
    "        \"output_tokens\": output_tokens\n",
    "    })\n",
    "\n",
    "avg_token_counts(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 제공해주신 텍스트 데이터를 구조화된 딕셔너리로 수동 파싱합니다.\n",
    "# 이 딕셔너리는 DataFrame 생성에 사용됩니다.\n",
    "data_raw = {\n",
    "    'Expert': {\n",
    "        'gpt-4o-mini': {\n",
    "            'Dog': {\n",
    "                'preprocessed': {'ROUGE': 0.261, 'BERTScore': 0.723, 'Factuality': 0.646},\n",
    "                'raw': {'ROUGE': 0.265, 'BERTScore': 0.722, 'Factuality': 0.647}\n",
    "            },\n",
    "            'Cat': {\n",
    "                'preprocessed': {'ROUGE': 0.271, 'BERTScore': 0.727, 'Factuality': 0.613},\n",
    "                'raw': {'ROUGE': 0.270, 'BERTScore': 0.724, 'Factuality': 0.606}\n",
    "            }\n",
    "        },\n",
    "        'claude-3-haiku': {\n",
    "            'Dog': {\n",
    "                'preprocessed': {'ROUGE': 0.248, 'BERTScore': 0.705, 'Factuality': 0.638},\n",
    "                'raw': {'ROUGE': 0.245, 'BERTScore': 0.699, 'Factuality': 0.622}\n",
    "            },\n",
    "            'Cat': {\n",
    "                'preprocessed': {'ROUGE': 0.251, 'BERTScore': 0.706, 'Factuality': 0.600},\n",
    "                'raw': {'ROUGE': 0.250, 'BERTScore': 0.702, 'Factuality': 0.577}\n",
    "            }\n",
    "        },\n",
    "        'gemini-2.0-flash': {\n",
    "            'Dog': {\n",
    "                'preprocessed': {'ROUGE': 0.253, 'BERTScore': 0.708, 'Factuality': 0.640},\n",
    "                'raw': {'ROUGE': 0.248, 'BERTScore': 0.701, 'Factuality': 0.633}\n",
    "            },\n",
    "            'Cat': {'preprocessed': {'ROUGE': 0.252, 'BERTScore': 0.708, 'Factuality': 0.617},\n",
    "                    'raw': {'ROUGE': 0.249, 'BERTScore': 0.701, 'Factuality': 0.604}}\n",
    "        },\n",
    "        'gemma-3-4b': {\n",
    "            'Dog': {'preprocessed': {'ROUGE': 0.234, 'BERTScore': 0.694, 'Factuality': 0.602},\n",
    "                    'raw': {'ROUGE': 0.232, 'BERTScore': 0.697, 'Factuality': 0.591}},\n",
    "            'Cat': {'preprocessed': {'ROUGE': 0.238, 'BERTScore': 0.697, 'Factuality': 0.573},\n",
    "                    'raw': {'ROUGE': 0.235, 'BERTScore': 0.699, 'Factuality': 0.564}}\n",
    "        },\n",
    "        'qwen-2.5-7b': {\n",
    "            'Dog': {'preprocessed': {'ROUGE': 0.202, 'BERTScore': 0.707, 'Factuality': 0.540},\n",
    "                    'raw': {'ROUGE': 0.206, 'BERTScore': 0.703, 'Factuality': 0.503}},\n",
    "            'Cat': {'preprocessed': {'ROUGE': 0.211, 'BERTScore': 0.709, 'Factuality': 0.506},\n",
    "                    'raw': {'ROUGE': 0.209, 'BERTScore': 0.706, 'Factuality': 0.516}}\n",
    "        },\n",
    "        'exaone-3.5-7.8b': {\n",
    "            'Dog': {'preprocessed': {'ROUGE': 0.243, 'BERTScore': 0.715, 'Factuality': 0.634},\n",
    "                    'raw': {'ROUGE': 0.243, 'BERTScore': 0.711, 'Factuality': 0.626}},\n",
    "            'Cat': {'preprocessed': {'ROUGE': 0.246, 'BERTScore': 0.713, 'Factuality': 0.575},\n",
    "                    'raw': {'ROUGE': 0.242, 'BERTScore': 0.708, 'Factuality': 0.575}}\n",
    "        }\n",
    "    },\n",
    "    'Non Expert': {\n",
    "        'gpt-4o-mini': {\n",
    "            'Dog': {'preprocessed': {'ROUGE': 0.239, 'BERTScore': 0.713, 'Factuality': 0.487},\n",
    "                    'raw': {'ROUGE': 0.245, 'BERTScore': 0.716, 'Factuality': 0.515}},\n",
    "            'Cat': {'preprocessed': {'ROUGE': 0.239, 'BERTScore': 0.717, 'Factuality': 0.460},\n",
    "                    'raw': {'ROUGE': 0.236, 'BERTScore': 0.716, 'Factuality': 0.467}}\n",
    "        },\n",
    "        'claude-3-haiku': {\n",
    "            'Dog': {'preprocessed': {'ROUGE': 0.217, 'BERTScore': 0.693, 'Factuality': 0.478},\n",
    "                    'raw': {'ROUGE': 0.216, 'BERTScore': 0.689, 'Factuality': 0.482}},\n",
    "            'Cat': {'preprocessed': {'ROUGE': 0.221, 'BERTScore': 0.695, 'Factuality': 0.455},\n",
    "                    'raw': {'ROUGE': 0.217, 'BERTScore': 0.691, 'Factuality': 0.433}}\n",
    "        },\n",
    "        'gemini-2.0-flash': {\n",
    "            'Dog': {'preprocessed': {'ROUGE': 0.209, 'BERTScore': 0.690, 'Factuality': 0.457},\n",
    "                    'raw': {'ROUGE': 0.209, 'BERTScore': 0.685, 'Factuality': 0.478}},\n",
    "            'Cat': {'preprocessed': {'ROUGE': 0.219, 'BERTScore': 0.697, 'Factuality': 0.446},\n",
    "                    'raw': {'ROUGE': 0.213, 'BERTScore': 0.688, 'Factuality': 0.440}}\n",
    "        },\n",
    "        'gemma-3-4b': {\n",
    "            'Dog': {'preprocessed': {'ROUGE': 0.194, 'BERTScore': 0.679, 'Factuality': 0.430},\n",
    "                    'raw': {'ROUGE': 0.197, 'BERTScore': 0.681, 'Factuality': 0.405}},\n",
    "            'Cat': {'preprocessed': {'ROUGE': 0.199, 'BERTScore': 0.687, 'Factuality': 0.414},\n",
    "                    'raw': {'ROUGE': 0.196, 'BERTScore': 0.687, 'Factuality': 0.414}}\n",
    "        },\n",
    "        'qwen-2.5-7b': {\n",
    "            'Dog': {'preprocessed': {'ROUGE': 0.197, 'BERTScore': 0.709, 'Factuality': 0.421},\n",
    "                    'raw': {'ROUGE': 0.196, 'BERTScore': 0.705, 'Factuality': 0.415}},\n",
    "            'Cat': {'preprocessed': {'ROUGE': 0.207, 'BERTScore': 0.714, 'Factuality': 0.383},\n",
    "                    'raw': {'ROUGE': 0.206, 'BERTScore': 0.709, 'Factuality': 0.386}}\n",
    "        },\n",
    "        'exaone-3.5-7.8b': {\n",
    "            'Dog': {'preprocessed': {'ROUGE': 0.211, 'BERTScore': 0.700, 'Factuality': 0.435},\n",
    "                    'raw': {'ROUGE': 0.206, 'BERTScore': 0.697, 'Factuality': 0.442}},\n",
    "            'Cat': {'preprocessed': {'ROUGE': 0.210, 'BERTScore': 0.704, 'Factuality': 0.416},\n",
    "                    'raw': {'ROUGE': 0.203, 'BERTScore': 0.697, 'Factuality': 0.394}}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# 중첩된 딕셔너리를 pandas DataFrame으로 평탄화합니다.\n",
    "flat_data = []\n",
    "for expertise, models_data in data_raw.items():\n",
    "    for model, animals_data in models_data.items():\n",
    "        for animal, process_types_data in animals_data.items():\n",
    "            for process_type, metrics_data in process_types_data.items():\n",
    "                row = {\n",
    "                    'Expertise': expertise,\n",
    "                    'Model': model,\n",
    "                    'Animal': animal,\n",
    "                    'ProcessType': process_type,\n",
    "                    **metrics_data # ROUGE, BERTScore, Factuality 지표들을 언팩하여 추가\n",
    "                }\n",
    "                flat_data.append(row)\n",
    "\n",
    "df_all = pd.DataFrame(flat_data)\n",
    "\n",
    "# 성능 시각화를 위한 함수를 정의합니다.\n",
    "def plot_performance(df_data, title, file_prefix):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    bar_width = 0.5\n",
    "\n",
    "    # 스택 바 차트를 위한 지표별 시작 위치 계산\n",
    "    df_data['BERTScore_bottom'] = 0\n",
    "    df_data['Factuality_bottom'] = df_data['BERTScore']\n",
    "    df_data['ROUGE_bottom'] = df_data['BERTScore'] + df_data['Factuality']\n",
    "\n",
    "    # zorder를 설정하여 막대가 그리드 선 위에 오도록 플로팅합니다.\n",
    "    ax.bar(df_data['Model'], df_data['BERTScore'], bar_width, label='BERTScore', color='#6cace4', bottom=df_data['BERTScore_bottom'], zorder=3)\n",
    "    ax.bar(df_data['Model'], df_data['Factuality'], bar_width, label='Factuality', color='#e77471', bottom=df_data['Factuality_bottom'], zorder=3)\n",
    "    ax.bar(df_data['Model'], df_data['ROUGE'], bar_width, label='ROUGE', color='#fdd069', bottom=df_data['ROUGE_bottom'], zorder=3)\n",
    "\n",
    "    # y축 눈금 및 그리드 선을 설정합니다.\n",
    "    y_ticks = np.arange(0, 2.25, 0.25) # 0부터 2.0까지 0.25 간격으로 눈금 설정\n",
    "    ax.set_yticks(y_ticks)\n",
    "    ax.yaxis.grid(True, linestyle='--', alpha=0.7, zorder=0) # 그리드 선은 실선으로, 투명도 및 zorder 설정\n",
    "\n",
    "    # 레이블 및 제목 설정\n",
    "    ax.set_xlabel('Models', fontsize=12)\n",
    "    ax.set_ylabel('Score', fontsize=12)\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_ylim(0, 2.0) # y축 범위 설정\n",
    "\n",
    "    # x축 레이블 회전\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "    # 범례 표시\n",
    "    ax.legend(loc='upper right', fontsize=10)\n",
    "\n",
    "    plt.tight_layout() # 레이아웃 자동 조정\n",
    "    plt.savefig(f\"visualization_results/{file_prefix}.png\")\n",
    "    plt.close(fig) # 메모리 해제를 위해 figure 닫기\n",
    "\n",
    "# 생성할 4가지 시각화의 설정을 정의합니다.\n",
    "plot_configs = [\n",
    "    {'expertise': 'Expert', 'animal': 'Dog', 'process_type': 'preprocessed', 'title': 'Expert - Dog - Preprocessed'},\n",
    "    {'expertise': 'Expert', 'animal': 'Cat', 'process_type': 'preprocessed', 'title': 'Expert - Cat - Preprocessed'},\n",
    "    {'expertise': 'Non Expert', 'animal': 'Dog', 'process_type': 'preprocessed', 'title': 'Non Expert - Dog - Preprocessed'},\n",
    "    {'expertise': 'Non Expert', 'animal': 'Cat', 'process_type': 'preprocessed', 'title': 'Non Expert - Cat - Preprocessed'},\n",
    "    {'expertise': 'Expert', 'animal': 'Dog', 'process_type': 'raw', 'title': 'Expert - Dog - Raw'},\n",
    "    {'expertise': 'Expert', 'animal': 'Cat', 'process_type': 'raw', 'title': 'Expert - Cat - Raw'},\n",
    "    {'expertise': 'Non Expert', 'animal': 'Dog', 'process_type': 'raw', 'title': 'Non Expert - Dog - Raw'},\n",
    "    {'expertise': 'Non Expert', 'animal': 'Cat', 'process_type': 'raw', 'title': 'Non Expert - Cat - Raw'}\n",
    "]\n",
    "\n",
    "# 각 설정에 따라 데이터를 필터링하고 플로팅 함수를 호출합니다.\n",
    "for i, config in enumerate(plot_configs):\n",
    "    title = config['title']\n",
    "    subset_df = df_all[\n",
    "        (df_all['Expertise'] == config['expertise']) &\n",
    "        (df_all['Animal'] == config['animal']) &\n",
    "        (df_all['ProcessType'] == config['process_type'])\n",
    "    ].copy() # SettingWithCopyWarning을 피하기 위해 .copy() 사용\n",
    "\n",
    "    plot_performance(subset_df, config['title'], f\"{title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expertise</th>\n",
       "      <th>Model</th>\n",
       "      <th>Animal</th>\n",
       "      <th>ProcessType</th>\n",
       "      <th>ROUGE</th>\n",
       "      <th>BERTScore</th>\n",
       "      <th>Factuality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Expert</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>Dog</td>\n",
       "      <td>preprocessed</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Expert</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>Dog</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Expert</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>Cat</td>\n",
       "      <td>preprocessed</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Expert</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>Cat</td>\n",
       "      <td>raw</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Expert</td>\n",
       "      <td>claude-3-haiku</td>\n",
       "      <td>Dog</td>\n",
       "      <td>preprocessed</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Expertise           Model Animal   ProcessType  ROUGE  BERTScore  Factuality\n",
       "0    Expert     gpt-4o-mini    Dog  preprocessed  0.261      0.723       0.646\n",
       "1    Expert     gpt-4o-mini    Dog           raw  0.265      0.722       0.647\n",
       "2    Expert     gpt-4o-mini    Cat  preprocessed  0.271      0.727       0.613\n",
       "3    Expert     gpt-4o-mini    Cat           raw  0.270      0.724       0.606\n",
       "4    Expert  claude-3-haiku    Dog  preprocessed  0.248      0.705       0.638"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 첫 번째 이미지의 표에서 데이터를 추출하여 DataFrame으로 만듭니다.\n",
    "# 'Dog' 컬럼의 'preprocessed' 데이터를 사용합니다.\n",
    "data = {\n",
    "    'Model': ['gpt-4o-mini', 'claude-3-haiku', 'gemini-2.0-flash', 'gemma-3-4b', 'qwen-2.5-7b', 'exaone-3.5-7.8b'],\n",
    "    'ROUGE': [0.261, 0.248, 0.253, 0.234, 0.202, 0.243],\n",
    "    'BERTScore': [0.723, 0.705, 0.708, 0.694, 0.707, 0.715],\n",
    "    'Factuality': [0.646, 0.638, 0.640, 0.602, 0.540, 0.634]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 각 지표를 누적하여 그래프를 그립니다.\n",
    "# 일반적으로 BERTScore가 가장 크고, ROUGE와 Factuality는 그보다 작으므로\n",
    "# BERTScore, Factuality, ROUGE 순으로 누적하여 그리는 것이 두 번째 이미지와 유사합니다.\n",
    "# (단, 두 번째 이미지의 y축 스케일은 각 지표의 값 합계와 일치하는 것으로 보입니다.)\n",
    "\n",
    "# 스택 바 차트를 위한 각 지표의 시작 위치 계산\n",
    "# BERTScore가 가장 아래에, 그 위에 Factuality, 그 위에 ROUGE가 쌓이도록 합니다.\n",
    "df['BERTScore_bottom'] = 0\n",
    "df['Factuality_bottom'] = df['BERTScore']\n",
    "df['ROUGE_bottom'] = df['BERTScore'] + df['Factuality']\n",
    "\n",
    "# 그래프 생성\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "bar_width = 0.5\n",
    "\n",
    "# BERTScore 바\n",
    "ax.bar(df['Model'], df['BERTScore'], bar_width, label='BERTScore', color='#6cace4', bottom=df['BERTScore_bottom'], zorder=3)\n",
    "# Factuality 바\n",
    "ax.bar(df['Model'], df['Factuality'], bar_width, label='Factuality', color='#e77471', bottom=df['Factuality_bottom'], zorder=3)\n",
    "# ROUGE 바\n",
    "ax.bar(df['Model'], df['ROUGE'], bar_width, label='ROUGE', color='#fdd069', bottom=df['ROUGE_bottom'], zorder=3)\n",
    "\n",
    "y_ticks = np.arange(0, 2.25, 0.25) # 0부터 2.0까지 0.25 간격으로 (상한 포함을 위해 2.25로 설정)\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.yaxis.grid(True, linestyle='--', alpha=0.7) # 가로선을 점선이 아닌 실선으로, 투명도 조정\n",
    "\n",
    "# 레이블 및 제목 설정\n",
    "ax.set_xlabel('Model', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Dog', fontsize=14)\n",
    "ax.set_ylim(0, 2.0)\n",
    "\n",
    "# x축 레이블 회전 (모델 이름이 길 경우)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# 범례 표시\n",
    "ax.legend(loc='upper right') # 범례 위치 조정\n",
    "\n",
    "plt.tight_layout() # 레이아웃 자동 조정\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/work/factchecking/miniconda3/envs/vllm/bin/python\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thierry Henry is a French coach.', 'Thierry Henry is a professional coach.', 'Thierry Henry is a football coach.', 'He was born in 1977.']\n",
      "['Atomic fact one.', 'Atomic fact two.', 'Another fact.']\n"
     ]
    }
   ],
   "source": [
    "def parse_atomic_facts_output(text):\n",
    "    \"\"\"\n",
    "    주어진 텍스트에서 '문장: ~' 부분을 제외하고 원자적 사실 목록을 추출합니다.\n",
    "    예시:\n",
    "    \"문장: Thierry Henry is a French professional football coach.\n",
    "    - Thierry Henry is a French coach.\n",
    "    - Thierry Henry is a professional coach.\n",
    "    - Thierry Henry is a football coach.\"\n",
    "    -> [\"Thierry Henry is a French coach.\", \"Thierry Henry is a professional coach.\", \"Thierry Henry is a football coach.\"]\n",
    "    \"\"\"\n",
    "    lines = text.strip().split('\\n')\n",
    "    atomic_facts = []\n",
    "\n",
    "    # 첫 번째 줄이 '문장: ~' 형식일 경우 건너뜁니다.\n",
    "    # 그 외의 경우, 모든 줄을 원자적 사실로 간주합니다.\n",
    "    start_index = 0\n",
    "    if lines and lines[0].startswith(\"문장:\"):\n",
    "        start_index = 1\n",
    "\n",
    "    for i in range(start_index, len(lines)):\n",
    "        line = lines[i].strip()\n",
    "        if line.startswith('- '):\n",
    "            fact = line[2:].strip() # '- ' 부분을 제거하고 공백을 정리합니다.\n",
    "            # 마지막 문자가 마침표가 아니면 추가합니다 (필요에 따라).\n",
    "            if fact and fact[-1] != '.':\n",
    "                fact += '.'\n",
    "            atomic_facts.append(fact)\n",
    "        elif line: # '- '로 시작하지 않지만 내용이 있는 줄도 사실로 간주할 경우 (선택 사항)\n",
    "            # 이 부분은 필요에 따라 주석 처리하거나 수정할 수 있습니다.\n",
    "            # 현재는 '- '로 시작하는 줄만 처리하도록 되어 있습니다.\n",
    "            pass\n",
    "            \n",
    "    return atomic_facts\n",
    "\n",
    "# 사용 예시:\n",
    "text_example = \"\"\"문장: Thierry Henry is a French professional football coach.\n",
    "- Thierry Henry is a French coach.\n",
    "- Thierry Henry is a professional coach.\n",
    "- Thierry Henry is a football coach.\n",
    "- He was born in 1977.\n",
    "\"\"\"\n",
    "\n",
    "facts = parse_atomic_facts_output(text_example)\n",
    "print(facts)\n",
    "\n",
    "text_example_no_sentence_header = \"\"\"- Atomic fact one.\n",
    "- Atomic fact two.\n",
    "- Another fact.\"\"\"\n",
    "\n",
    "facts_no_header = parse_atomic_facts_output(text_example_no_sentence_header)\n",
    "print(facts_no_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/work/factchecking/miniconda3/envs/vllm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "증상이 경한 감기일 수도 있지만, 심혈관계 질환이나 다른 질환일 수도 있습니다. 병원에 내원하여 검사받기를 권장합니다.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "use_raw_format = False\n",
    "model_name = \"exaone-3.5-7.8b\"\n",
    "suffix = \"raw\" if use_raw_format else \"preprocessed\"\n",
    "fintuned_path = f'data/outputs/{model_name}_petqa_{suffix}/best_model'\n",
    "\n",
    "system_prompt = \"당신은 반려동물(개, 고양이) 의료 상담 전문 수의사입니다.\\n당신의 역할은 개(강아지), 고양이 관련 의료 질문에 대해 유용하고, 완전하며, 전문적인 지식에 기반한 정확한 답변을 하는 것입니다.\\n질문에 대해 차근차근 생각하며 답변하고, 답변 문장의 개수는 최대 5개를 넘지 마세요.\"\n",
    "        \n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    fintuned_path,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    fintuned_path,\n",
    ")\n",
    "\n",
    "def generate_answer(model, tokenizer, question, system_prompt=None):\n",
    "    \"\"\"질문에 대한 답변 생성\"\"\"\n",
    "    \n",
    "    system_prompt = \"당신은 반려동물(개, 고양이) 의료 상담 전문 수의사입니다.\\n당신의 역할은 개(강아지), 고양이 관련 의료 질문에 대해 유용하고, 완전하며, 전문적인 지식에 기반한 정확한 답변을 하는 것입니다.\\n질문에 대해 차근차근 생각하며 답변하고, 답변 문장의 개수는 최대 5개를 넘지 마세요.\"\n",
    "    \n",
    "    # 메시지 구성\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    \n",
    "    # 채팅 템플릿 적용\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    # 토큰화\n",
    "    inputs = tokenizer(\n",
    "        prompt, \n",
    "        return_tensors=\"pt\", \n",
    "        truncation=True, \n",
    "        max_length=4096\n",
    "    )\n",
    "    \n",
    "    # GPU로 이동 (모델이 GPU에 있는 경우)\n",
    "    if model.device.type == 'cuda':\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    # 답변 생성\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=2048,\n",
    "            do_sample=False,\n",
    "            temperature=0,\n",
    "        )\n",
    "    \n",
    "    # 생성된 텍스트 디코딩 (입력 프롬프트 제외)\n",
    "    generated_tokens = outputs[0][inputs['input_ids'].shape[1]:]\n",
    "    generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "    \n",
    "    return generated_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경련의 원인은 다양하며, 뇌수두증, 후두골 이형성, 소뇌형성 부전, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌수막염, 뇌척수염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 뇌수두증, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 후두골형성 부전, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 뇌수두증, 뇌수막염, 뇌수두증, 뇌수두증, 뇌종양, 뇌수두증, 뇌수막염, 뇌수두증, 뇌수두증, 뇌종양, 뇌수막염, 뇌수두증, 뇌수두증, 뇌수막염, 뇌수두증, 뇌수두증, 뇌종양, 뇌수두증, 뇌수막염, 뇌수두증, 뇌수두증, 뇌종양, 뇌수두증, 뇌수막염, 뇌수두증, 뇌수두증, 뇌종양, 뇌수두증, 뇌수막염, 뇌수두증, 뇌수두증, 뇌종양, 뇌수두증, 뇌수막염, 뇌수두증, 뇌수두증, 뇌종양, 뇌수두증, 뇌수막염, 뇌수두증, 뇌수\n"
     ]
    }
   ],
   "source": [
    "question = \"질문: 강아지(코카 스파니엘, 4세, 11kg)가 2주 전부터 온몸이 뻣뻣해지며 경련을 일으켰고, 경련 후에는 밥을 먹지 않습니다. 최근에도 또 경련을 일으켰습니다. 어디에 문제가 있는지, 예상되는 질병은 무엇인지 알려주십시오.\\n답변: \"\n",
    "print(generate_answer(model, tokenizer, question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[PAD]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_on_train_samples(model, tokenizer, train_data, formatting_func, num_samples=5, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    학습에 사용된 train set 일부 샘플에 대해 모델 응답을 확인하는 함수\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Train 샘플 {num_samples}개에 대해 모델 응답 확인\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        sample = train_data[i]\n",
    "        prompt = formatting_func(sample)\n",
    "        \n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                input_ids=inputs[\"input_ids\"],\n",
    "                attention_mask=inputs[\"attention_mask\"],\n",
    "                max_new_tokens=256,\n",
    "                do_sample=True,\n",
    "                temperature=0.8,\n",
    "                top_p=0.95,\n",
    "                top_k=50,\n",
    "                repetition_penalty=1.2,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "                pad_token_id=tokenizer.pad_token_id\n",
    "            )\n",
    "\n",
    "        decoded_output = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        print(f\"\\n[Sample {i+1}]\")\n",
    "        print(\"-\" * 30)\n",
    "        print(\"[Prompt]\")\n",
    "        print(prompt)\n",
    "        print(\"\\n[Generated Answer]\")\n",
    "        print(decoded_output.replace(prompt, \"\").strip())  # 출력에서 프롬프트 제거\n",
    "        print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Valid JSON format\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "file_path = \"data/eval/output_exaone-3.5-7.8b_petqa_0.json\"\n",
    "with open(file_path, 'r') as f:\n",
    "    try:\n",
    "        data = json.load(f)\n",
    "        print(\"✅ Valid JSON format\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"❌ JSON decode error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "NVIDIA H100 80GB HBM3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CUDA not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(model, tokenizer, question, system_prompt=None):\n",
    "    \"\"\"질문에 대한 답변 생성\"\"\"\n",
    "    \n",
    "    # 기본 시스템 프롬프트 설정\n",
    "    if system_prompt is None:\n",
    "        system_prompt = \"당신은 반려동물(개, 고양이) 의료 상담 전문 수의사입니다.\\n당신의 역할은 개(강아지), 고양이 관련 의료 질문에 대해 유용하고, 완전하며, 전문적인 지식에 기반한 정확한 답변을 하는 것입니다.\\n답변 외의 문장은 포함하지 마세요.\"\n",
    "    \n",
    "    # 메시지 구성\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    \n",
    "    # 채팅 템플릿 적용\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    # 토큰화\n",
    "    inputs = tokenizer(\n",
    "        prompt, \n",
    "        return_tensors=\"pt\", \n",
    "        truncation=True, \n",
    "        max_length=4096\n",
    "    )\n",
    "    \n",
    "    # GPU로 이동 (모델이 GPU에 있는 경우)\n",
    "    if model.device.type == 'cuda':\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    \n",
    "    # 답변 생성\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=2048,\n",
    "            do_sample=True,\n",
    "            temperature=0.1,\n",
    "            top_p=0.1,\n",
    "            top_k=50,\n",
    "            repetition_penalty=1.2,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            use_cache=True\n",
    "        )\n",
    "    \n",
    "    # 생성된 텍스트 디코딩 (입력 프롬프트 제외)\n",
    "    generated_tokens = outputs[0][inputs['input_ids'].shape[1]:]\n",
    "    generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "    \n",
    "    return generated_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mexaone-3.5-7.8b\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m finetuned_path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdata/outputs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_petqa/best_model\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m tokenizer = AutoTokenizer.from_pretrained(\n\u001b[32m     12\u001b[39m     finetuned_path,\n\u001b[32m     13\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/factchecking/miniconda3/envs/vllm/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:564\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    562\u001b[39m     \u001b[38;5;28mcls\u001b[39m.register(config.\u001b[34m__class__\u001b[39m, model_class, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    563\u001b[39m     model_class = add_generation_mixin_to_remote_model(model_class)\n\u001b[32m--> \u001b[39m\u001b[32m564\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    565\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    566\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m._model_mapping.keys():\n\u001b[32m    568\u001b[39m     model_class = _get_model_class(config, \u001b[38;5;28mcls\u001b[39m._model_mapping)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/factchecking/miniconda3/envs/vllm/lib/python3.12/site-packages/transformers/modeling_utils.py:309\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    311\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/factchecking/miniconda3/envs/vllm/lib/python3.12/site-packages/transformers/modeling_utils.py:4285\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4283\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDeepSpeed Zero-3 is not compatible with passing a `device_map`.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4284\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[32m-> \u001b[39m\u001b[32m4285\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   4286\u001b[39m             (\n\u001b[32m   4287\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mUsing a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4288\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mrequires `accelerate`. You can install it with `pip install accelerate`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4289\u001b[39m             )\n\u001b[32m   4290\u001b[39m         )\n\u001b[32m   4292\u001b[39m \u001b[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001b[39;00m\n\u001b[32m   4293\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit \u001b[38;5;129;01mor\u001b[39;00m load_in_8bit:\n",
      "\u001b[31mValueError\u001b[39m: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`"
     ]
    }
   ],
   "source": [
    "model_id = \"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\"\n",
    "model_name = \"exaone-3.5-7.8b\"\n",
    "finetuned_path = f\"data/outputs/{model_name}_petqa/best_model\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "무릎골탈구 단계는 촉진 검사와 방사선 검사를 통한 종합적인 분석이 필요합니다. 무릎골탈구는 정도에 따라 1기~4기로 구분되며, 일반적으로 1기와 2기는 겉으로 확인하기 어렵고 3기에서는 수술을 추천드립니다. 진행된다면 파행 증상이 심해지고 자세 이상 및 퇴행성 관절염이 동반됩니다. 하루 30분 이상 꾸준한 산책과 체중 조절로 관절을 보호해야 하고 과격한 운동과 점프 같은 행동은 피해야 합니다. 관절 보조제를 통해 최대한 진행을 차단하시기 바랍니다. 주기적으로 병원에서 상황을 체크하시길 권장합니다.\n"
     ]
    }
   ],
   "source": [
    "question = \"강아지가 쓸개골 탈구가 의심됩니다. 앞으로 산책을 꾸준히 하면 탈구가 예방될까요?\"\n",
    "print(generate_answer(model, tokenizer, question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"./data/training\"\n",
    "train_path = os.path.join(train_dir, f\"train.json\")\n",
    "validation_path = os.path.join(train_dir, f\"validation.json\")\n",
    "\n",
    "data_files = {\n",
    "    \"train\": train_path,\n",
    "    \"validation\": validation_path\n",
    "}\n",
    "\n",
    "def load_datasets(data_files):\n",
    "    dataset = load_dataset(\"json\", data_files=data_files)\n",
    "    \n",
    "    train_data = dataset[\"train\"]\n",
    "    validation_data = dataset[\"validation\"]\n",
    "    \n",
    "    return train_data, validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
